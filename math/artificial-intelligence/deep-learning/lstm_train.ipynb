{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I.  Vanilla RNN (1 - 100 hidden)\n",
    "# II. LSTM (1 - 50 hidden)\n",
    "# III.LSTM (1 - 100 hidden)\n",
    "# IV. LSTM (1 - 150 hidden)\n",
    "# V.  LSTM (2 - 100 hidden)\n",
    "\n",
    "# Compare I and III\n",
    "# Pick Best From I ... V, then do 1 ... 5\n",
    "\n",
    "# 1. Maximum Output\n",
    "# 2. T = 0.5         \n",
    "# 3. T = 0.7\n",
    "# 4. T = 1             \n",
    "# 5. T = 2 \n",
    "\n",
    "# Compare 1, 3\n",
    "# Compare 2, 4, 5\n",
    "# Generate 2 ABC notation, music representation, midi file http://mandolintab.net/abcconverter.php\n",
    "# Pick Best From 3, 4, 5, then Generate Heatmap, run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 4, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Attirbutes\n",
    "        data     : list of [idx, string] - 1\n",
    "        one_hot\n",
    "    \"\"\"\n",
    "    def __init__(self, txt_file, id_ch, ch_id):\n",
    "        self.data = [\"\"]\n",
    "        self.id_ch, self.ch_id = ch_id, ch_id\n",
    "        self.dim = len(id_ch)\n",
    "\n",
    "        ne = 0\n",
    "        for line in open(txt_file, mode='r'):\n",
    "            if \"<start>\" in line:\n",
    "                continue\n",
    "            elif \"<end>\" in line:\n",
    "                self.data.append(\"\")\n",
    "            else:\n",
    "                self.data[len(self.data) - 1] += line\n",
    "        self.data.pop()\n",
    "        \n",
    "        self.computed = []\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            item = self.computeItem(i)\n",
    "            self.computed.append(item)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def computeItem(self, idx):\n",
    "        indices = [ch_id[ch] for ch in self.data[idx]]\n",
    "        targets = np.array(indices).reshape(-1)\n",
    "        one_hot = np.eye(self.dim)[targets]\n",
    "        label = np.zeros(one_hot.shape[0], dtype=np.int64)\n",
    "        label[0:label.shape[0]-1] = one_hot.argmax(axis=1)[1:one_hot.shape[0]] # shifted one to left\n",
    "        label[label.shape[0]-1] = ch_id['$'] # for end character\n",
    "        return (one_hot, label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            idx : n\n",
    "        Returns\n",
    "            str : one-hot encoded string\n",
    "        \"\"\"\n",
    "        return self.computed[idx]\n",
    "\n",
    "class RNN(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes): \n",
    "        super(RNN, self).__init__() \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out, hidden = self.rnn(input, hidden)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self): \n",
    "        self.hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size)).float().to(device)\n",
    "    \n",
    "class LSTM(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes): \n",
    "        super(LSTM, self).__init__() \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input  : [seq_len, batch_size, input_]\n",
    "        Returns:\n",
    "            out    : [seq_len, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        out, (self.hs, self.cs) = self.lstm(input, (self.hs.detach(), self.cs.detach()))\n",
    "        return self.fc(out.view(-1, self.hidden_size))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            hidden : [layer_len, batch_size, hidden_size] * 2 (pair)\n",
    "        \"\"\"\n",
    "        self.hs = Variable(torch.zeros(self.num_layers, 1, self.hidden_size)).float().to(device)\n",
    "        self.cs = Variable(torch.zeros(self.num_layers, 1, self.hidden_size)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_ch, ch_id = {0:'$'}, {'$':0}\n",
    "idx = 1\n",
    "\n",
    "for line in open('train.txt', mode='r'):\n",
    "    if \"<start>\" in line:\n",
    "        continue\n",
    "    elif \"<end>\" in line:\n",
    "        continue\n",
    "    else:\n",
    "        for ch in line:\n",
    "            if ch not in ch_id:\n",
    "                ch_id[ch] = idx\n",
    "                id_ch[idx] = ch\n",
    "                idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset('train.txt', id_ch, ch_id)\n",
    "valid_dataset = dataset('val.txt', id_ch, ch_id)\n",
    "test_dataset = dataset('test.txt', id_ch, ch_id)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(list(range(len(train_dataset))))\n",
    "valid_sampler = SubsetRandomSampler(list(range(len(valid_dataset))))\n",
    "test_sampler = SubsetRandomSampler(list(range(len(test_dataset))))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"3/\"\n",
    "model = LSTM(input_size = 94, hidden_size = 100, num_layers = 1, num_classes = 94).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(25):\n",
    "    print(\"Training Epoch {}\".format(epoch))\n",
    "    train_loss, valid_loss, train_count, valid_count = 0, 0, 0, 0\n",
    "    for minibatch_count, (notes, labels) in enumerate(train_loader, 0):\n",
    "        chunk = math.ceil(notes.shape[1] / 100)\n",
    "        model.init_hidden()\n",
    "        for i in range(chunk):\n",
    "            optimizer.zero_grad()\n",
    "            train_count += 1\n",
    "            output = model(notes[:, i * 100: i * 100 + 100, :].float().to(device))\n",
    "            batch_loss = criterion(output, labels[0, i * 100: i*100+100].to(device))\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += batch_loss.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for minibatch_count, (notes, labels) in enumerate(valid_loader, 0):\n",
    "            chunk = math.ceil(notes.shape[1] / 100)\n",
    "            model.init_hidden()\n",
    "            for i in range(chunk):\n",
    "                valid_count += 1\n",
    "                output = model(notes[:, i * 100: i * 100 + 100, :].float().to(device))\n",
    "                batch_loss = criterion(output, labels[0, i * 100: i*100+100].to(device))\n",
    "                valid_loss += batch_loss.item()\n",
    "                \n",
    "    train_loss /= train_count\n",
    "    valid_loss /= valid_count\n",
    "    \n",
    "    print(train_loss, valid_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    torch.save(model.state_dict(), PATH + str(epoch))\n",
    "    if len(valid_losses) > 10 and valid_losses[-3] < valid_loss:\n",
    "        break\n",
    "\n",
    "tlfile = open(PATH + \"trainloss.txt\", \"w\")\n",
    "vlfile = open(PATH + \"validloss.txt\", \"w\")\n",
    "tlfile.write(\",\".join(str(l) for l in train_losses))\n",
    "vlfile.write(\",\".join(str(l) for l in valid_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}