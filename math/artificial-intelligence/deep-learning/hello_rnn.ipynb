{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYd22fw5h5UlZ9uOLqfIBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/SeanHwangG/90c8434a8f53cdac9561cdd6624a101e/untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31LrQwaDuPbN",
        "outputId": "d5b5c40d-e0a2-4817-a64f-1658320f1685"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "input_size, hidden_size, batch_size = 6, 6, 1\n",
        "num_layers = 1\n",
        "\n",
        "idx2char = ['h', 'i', 'e', 'l', 'o', ' '] \n",
        "x_data = [0, 1, 0, 2, 3, 3, 0] # h i h e l l h\n",
        "y_data = [1, 5, 0, 2, 3, 3, 4] # i   h e l l o\n",
        "inputs = nn.functional.one_hot(torch.LongTensor(x_data).view(-1,1), input_size).float()\n",
        "labels = Variable(torch.LongTensor(y_data))\n",
        "\n",
        "class Model(nn.Module): \n",
        "    def __init__(self): \n",
        "        super(Model, self).__init__() \n",
        "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, batch_first = True) \n",
        "        \n",
        "    def forward(self, x, hidden): \n",
        "        x = x.view(batch_size, len(x_data), input_size) \n",
        "        out, hidden = self.rnn(x, hidden) \n",
        "        out = out.view(-1, len(idx2char))\n",
        "        return hidden, out \n",
        "    \n",
        "    def init_hidden(self): \n",
        "        return Variable(torch.zeros(num_layers, batch_size, hidden_size))\n",
        "\n",
        "model = Model()\n",
        "print(model)\n",
        "criterion = torch.nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1) \n",
        "hidden = model.init_hidden()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (rnn): RNN(6, 6, batch_first=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUykzSNGuQ6u",
        "outputId": "92dc77e7-0c31-4df0-db9a-67e4b3517c9e"
      },
      "source": [
        "for epoch in range(10): \n",
        "    _, outputs = model(inputs, hidden) \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "    _, idx = outputs.max(1)\n",
        "    idx = idx.data.numpy()\n",
        "    \n",
        "    result_str = [idx2char[c] for c in idx.squeeze()] \n",
        "    print(f\"epoch: {epoch + 1}, loss: {loss.item():.3f} \\t {''.join(result_str)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, loss: 1.874 \t eeeeeei\n",
            "epoch: 2, loss: 1.576 \t h ellli\n",
            "epoch: 3, loss: 1.308 \t h hlllo\n",
            "epoch: 4, loss: 1.094 \t o hello\n",
            "epoch: 5, loss: 1.024 \t o hello\n",
            "epoch: 6, loss: 0.959 \t o hello\n",
            "epoch: 7, loss: 0.888 \t h hello\n",
            "epoch: 8, loss: 0.826 \t i hello\n",
            "epoch: 9, loss: 0.781 \t i hello\n",
            "epoch: 10, loss: 0.744 \t i hello\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}