{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eabf93ae2e638406e35e0e41afbf354b",
     "grade": false,
     "grade_id": "cell-50cd7d156830d619",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1\n",
    "\n",
    "#### Please copy and paste your code in the functions below.\n",
    "#### Please do not add or remove any cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student 1 Name: Gyuseung Sean Hwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9aa0aa40ef9de8238dfe3617acbd9a23",
     "grade": false,
     "grade_id": "cell-12019b2aab71919f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "24cae431b991612048b762433e093992",
     "grade": false,
     "grade_id": "cell-4486cbb7b54842e9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cleanup(intext):\n",
    "    '''\n",
    "    cleanup method cleans up the intext string of punctuation,\n",
    "    numbers and stop words etc. and returns a lower case string.\n",
    "    1. Replace all occurences of \"!\" with the word \"ExclamationMark\" (already done for you)\n",
    "    2. Replace all occurences of \"?\" with the word \"QuestionMark\" (already done for you)\n",
    "    3. Replace all punctuations with empty string. Hint: use string.punctuation\n",
    "        Note: words like \"don't\" change into \"dont\"\n",
    "    4. Replace all digits with empty string. Hint: use string.digits\n",
    "    5. Make sure all words are seperated by a single space.\n",
    "    6. Remove all stop words (already defiined for you)\n",
    "    7. Return the cleaned up string.\n",
    "    '''\n",
    "    \n",
    "    stopWords = {'a', 'br', 'this', 'an', 'be', 'are', 'hers', 'able', 'about', 'its', 'then', 'in', 'is', 'at', 'from', 'am', 'his', 'and', 'these', 'him', 'he', 'of', 'them', 'on', 'to', 'for', 'than', 'by', 'since', 'as', 'that', 'their', 'it', 'the', 'her', 'there', 'or'}\n",
    "    \n",
    "    intext = intext.replace(\"!\", \" ExclamationMark \")\n",
    "    intext = intext.replace(\"?\", \" QuestionMark \")\n",
    "    \n",
    "    for digit in string.digits:\n",
    "        intext = intext.replace(digit, \"\")\n",
    "\n",
    "    for digit in string.punctuation:\n",
    "        intext = intext.replace(digit, \"\")\n",
    "    \n",
    "    ret = \"\"\n",
    "    \n",
    "    for word in intext.split():\n",
    "        word = word.lower()\n",
    "        if word not in stopWords:\n",
    "            ret += word + \" \"\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1850038198778adf4cb5341d8e01c30",
     "grade": true,
     "grade_id": "cell-e5a2c033c0167a99",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a simple test for you to test your cleanup function.\n",
    "assert cleanup(\"Great movie! GREAT!\").split() == ['great', 'movie', 'exclamationmark', 'great', 'exclamationmark']\n",
    "assert cleanup(\"I have seen 12345 movies like this.\").split() == [\"i\", \"have\", \"seen\", \"movies\", \"like\"]\n",
    "assert cleanup(\"This movie is bad! I don't like it....\").split() == ['movie', 'bad', 'exclamationmark', 'i', 'dont', 'like']\n",
    "assert cleanup(\"I don't know what to say! )*&$%^#$*@(^&)\").split() == ['i', 'dont', 'know', 'what', 'say', 'exclamationmark']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b6f98f3cbe2ade7aed60a2a2d23a5365",
     "grade": false,
     "grade_id": "cell-07dff50164bd24ac",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def directory2Vocab(dirName, outputFileName):\n",
    "    '''\n",
    "    create a set that contains words in all reviews\n",
    "    write the words in vocab.txt (one word per line)\n",
    "    order doesn't matter\n",
    "    '''\n",
    "    vocabSet = set()   #start with an empty set\n",
    "    \n",
    "    # open a new file, outputFileName, in the “w” mode.\n",
    "    fileName = outputFileName\n",
    "    vocabFile = open(fileName,'w')\n",
    "    \n",
    "    allFiles = os.listdir(dirName)\n",
    "    \n",
    "    for review in allFiles:\n",
    "        file = open(dirName + \"/\" + review, 'r')\n",
    "        for string in cleanup(file.read()).split():\n",
    "            vocabSet.add(string)\n",
    "    \n",
    "    #finally write the contents of the vocab set in the vocabfile, one word per line\n",
    "    vocabList = list(vocabSet)\n",
    "    for word in vocabList:\n",
    "        vocabFile.write(word+'\\n')\n",
    "    vocabFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c08e5db925186c3e605c96d1dd19f4f2",
     "grade": true,
     "grade_id": "cell-d36f6025a1bfaa4e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to make sure you have the vocab files created after run.\n",
    "directory2Vocab('MovieReviews_subset', 'Vocab.txt')\n",
    "assert os.path.isfile('Vocab.txt') == True\n",
    "\n",
    "vocabFile = open('Vocab.txt', 'r')\n",
    "vocab = vocabFile.readlines()\n",
    "\n",
    "### Make sure there are 1127 words in the vocab file generated from reviews in MovieReviews_subset directory\n",
    "assert len(vocab) == 1127\n",
    "\n",
    "# Test you make sure you have the following words in your vocab\n",
    "assert (\"all\\n\" in vocab) == True\n",
    "assert (\"zero\\n\" in vocab) == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "054b69e64678c94ce86aec3297ab5fb8",
     "grade": true,
     "grade_id": "cell-610d012cae422602",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to make sure you have punctuations, stop_words, digits removed\n",
    "vocabFile = open('Vocab.txt', 'r')\n",
    "vocab = vocabFile.readlines()\n",
    "assert (\"a\\n\" in vocab) == False\n",
    "assert (\".\\n\" in vocab) == False\n",
    "assert (\"3\\n\" in vocab) == False\n",
    "\n",
    "stop_words = [' a ', ' able ', ' about ', ' am ', ' an ', ' and ', ' are ', ' as ', ' at ', ' be ', ' by ', ' for ', ' from ', ' he ', ' her ', ' hers ', ' him ', ' his ', ' in ', ' is ', ' it ', ' its ', ' of ', ' on ', ' or ', ' since ', ' than ', ' that ', ' the ', ' their ', ' them ', ' then ', ' there ', ' these ',  ' this ', ' to ']\n",
    "for s in stop_words:\n",
    "    assert (s.strip() + '\\n' in vocab) == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4d670419b298fca75481501ef4948ca9",
     "grade": false,
     "grade_id": "cell-95b6b48ca2eca489",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def directory2Features(dirName, vocabfilename):\n",
    "    '''\n",
    "    create feature vector for each review\n",
    "    Format each feature vector as following:\n",
    "    rating word1_index:word1_count word2_index:word2_count word3_index:word3_count ...\n",
    "    index must be in increasing order\n",
    "    \n",
    "    for example:\n",
    "    4 0:3 3:2 10:2 33:1 53:2 78:1 241:2\n",
    "    \n",
    "    write all feature vectors to file <dirName>_fVectors.txt\n",
    "    '''\n",
    "    \n",
    "    # open and read the vocabfilename\n",
    "    # put each word in vocabfile as an element in a list.\n",
    "    vocFile = open(vocabfilename, 'r') #Open the vocab file\n",
    "    vocabWords = vocFile.read().splitlines()\n",
    "    \n",
    "    # open a new file, <dirName>_fVectors.txt, in the “w” mode.\n",
    "    vecFileName = dirName.split(\"/\")[0]+'_fVectors.txt'\n",
    "    fVectors = open(vecFileName, 'w')\n",
    "    \n",
    "    allFiles = os.listdir(dirName)\n",
    "    for f in allFiles:\n",
    "        #open file in read format\n",
    "        #read file as a string\n",
    "        file = os.path.join(dirName,f)\n",
    "        reviewFile = open(file, 'r')\n",
    "        allContent = reviewFile.read()\n",
    "        \n",
    "        # 1. write code to clean up the string by calling cleanup method\n",
    "        allContent = cleanup(allContent)\n",
    "        # 2. extract rating from the file name, f.\n",
    "        rating = f.split(\"_\")[0]\n",
    "        # 3. Create the feature vector to the rating\n",
    "        fVector = rating\n",
    "        counter = {}\n",
    "        for word in allContent.split():\n",
    "            wordIndex = vocabWords.index(word)\n",
    "            if wordIndex in counter:\n",
    "                counter[wordIndex]+=1\n",
    "            else:\n",
    "                counter[wordIndex]=1\n",
    "            \n",
    "        for wIndex in sorted(counter.keys()):\n",
    "            fVector += \" \" + str(wIndex) + \":\" + str(counter[wIndex])\n",
    "        \n",
    "        # 5. Append the feature vector to the rating and write it to the fVectors file\n",
    "        fVectors.write(fVector + \"\\n\")\n",
    "        \n",
    "    vocFile.close()\n",
    "    fVectors.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b033b984d4a2b26566ff3f98a8187fb1",
     "grade": true,
     "grade_id": "cell-54788abc11cd108e",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to make sure you have the fVectors files created after run.\n",
    "directory2Features('MovieReviews_subset', \"Vocab.txt\")\n",
    "assert os.path.isfile('MovieReviews_subset_fVectors.txt') == True\n",
    "\n",
    "vecFile = open('MovieReviews_subset_fVectors.txt', 'r')\n",
    "vec = vecFile.readlines()\n",
    "\n",
    "### Make sure there are 22 lines in the fVectors file generated from reviews in MovieReviews_subset directory\n",
    "### (one line per review)\n",
    "assert len(vec) == 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1f23f3503940d49a890d5b7c4f502a3c",
     "grade": true,
     "grade_id": "cell-a12d9ac00597ff5e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test on the complete dataset\n",
    "directory2Vocab('MovieReviews_full/', 'Vocab_full.txt')\n",
    "assert os.path.isfile('Vocab_full.txt') == True\n",
    "\n",
    "# Test to make sure you have punctuations, stop_words, digits removed\n",
    "vocabFile = open('Vocab_full.txt', 'r')\n",
    "vocab = vocabFile.readlines()\n",
    "assert (\"a\\n\" in vocab) == False\n",
    "assert (\".\\n\" in vocab) == False\n",
    "assert (\"3\\n\" in vocab) == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "715d4b1309c2ff925e8a77921d6f7f8c",
     "grade": false,
     "grade_id": "cell-6d0863d6639d3f38",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def createFeatureVectors(dirName, vocabFile):\n",
    "    directory2Vocab(dirName, vocabFile)\n",
    "    directory2Features(dirName, vocabFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb8e0f7369e9e508c3460027efc67ef7",
     "grade": false,
     "grade_id": "cell-36df241f2711aaff",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Running createFeatureVectors(\"MovieReviews_Example/\", \"Vocab_Example.txt\") generates 2 files:\n",
    "## 1. Vocab_Example.txt\n",
    "## 2. MovieReviews_Example_fVectors.txt\n",
    "\n",
    "### The Vocab_Example.txt file contains 434 words\n",
    "### MovieReviews_Example_fVectors.txt contains 5 lines: 1 line per review.\n",
    "\n",
    "### These 2 files are already provided to you to confirm your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "createFeatureVectors(\"MovieReviews_Example/\", \"Vocab_Example.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
