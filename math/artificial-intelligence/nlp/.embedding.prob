> hackerrank

* [Level Easy : Compute the Cross-Entropy](https://www.hackerrank.com/challenges/nlp-compute-the-cross-entropy/problem)
  * [Update solution](https://github.com/seanhwangg/blog/tree/main/math/artificial-intelligence/nlp/embedding/HR_nlp-compute-the-cross-entropy.md/)

{% tabs %}
{% tab title='HR_nlp-compute-the-cross-entropy.md' %}

> Question

* Given perplexity of a bigram model, compute its cross-entropy corrected to 2 decimal places

```txt
Input: 170
Output: 7.41
```

{% endtab %}
{% tab title='HR_nlp-compute-the-cross-entropy.py' %}

```py
import math
print(math.log2(int(input())))
```

{% endtab %}
{% endtabs %}
